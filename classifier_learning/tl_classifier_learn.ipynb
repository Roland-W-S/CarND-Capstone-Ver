{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traddif light classifier learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data list\n",
    "PATH_IMG_LIST_CSV=\"../ros/src/tl_detector/training_data/data.csv\"\n",
    "PATH_IMG_DIR=\"../ros/src/tl_detector\"\n",
    "img_list_csv=pd.read_csv(PATH_IMG_LIST_CSV,sep=',',header=None)\n",
    "cls=img_list_csv[1]\n",
    "filenames=img_list_csv[0]\n",
    "data_num=len(cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x163bfb49be0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Test resizing\n",
    "fn=filenames[726]\n",
    "image_bgr = cv2.imread(PATH_IMG_DIR+\"/\"+fn)\n",
    "image=cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image.astype(np.uint8))\n",
    "plt.imshow(cv2.resize(image,(32,32)).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "batch_size=32\n",
    "learning_rate=1e-4\n",
    "resized_width=32\n",
    "resized_height=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images\n",
    "#resize 600,800->32,32\n",
    "\n",
    "data=np.zeros([filenames.shape[0],resized_height,resized_width,3])\n",
    "for i,fn in enumerate(filenames):\n",
    "    image_bgr = cv2.imread(PATH_IMG_DIR+\"/\"+fn)\n",
    "    image=cv2.cvtColor(image_bgr, cv2.COLOR_BGR2HSV)\n",
    "    data[i,:,:,:]=cv2.resize(image,(resized_height,resized_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data\n",
    "\n",
    "#Shuffle data\n",
    "np.random.seed(0)\n",
    "shuffle_idx=np.random.permutation(cls.shape[0])\n",
    "\n",
    "#Split data indices\n",
    "train_num=int(data_num*0.6)\n",
    "test_num=int(data_num*0.2)\n",
    "val_num=data_num-train_num-test_num\n",
    "train_idx=shuffle_idx[:train_num]\n",
    "test_idx=shuffle_idx[train_num:train_num+test_num]\n",
    "val_idx=shuffle_idx[train_num+test_num:]\n",
    "\n",
    "#Save indices\n",
    "np.savetxt(\"dataset_train.csv\",train_idx)\n",
    "np.savetxt(\"dataset_test.csv\",test_idx)\n",
    "np.savetxt(\"dataset_val.csv\",val_idx)\n",
    "\n",
    "#Split data\n",
    "train_cls=cls[train_idx]\n",
    "train_data=data[train_idx]\n",
    "test_cls=cls[test_idx]\n",
    "test_data=data[test_idx]\n",
    "val_cls=cls[val_idx]\n",
    "val_data=data[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define model\n",
    "\n",
    "#Input\n",
    "x_input_shape=(None,resized_width,resized_height,3)\n",
    "y_input_shape=(None,)\n",
    "x_input=tf.placeholder(tf.float32,shape=x_input_shape,name=\"x_input\")\n",
    "y_input=tf.placeholder(tf.int32,shape=y_input_shape,name=\"y_input\")\n",
    "y_input_onehot=tf.one_hot(y_input, depth=3, dtype=tf.float32)\n",
    "\n",
    "#conv 1\n",
    "#32*32 -> 32*32 *32\n",
    "conv1_w=tf.Variable(tf.truncated_normal([3,3,3,32]))\n",
    "conv1_b=tf.Variable(tf.truncated_normal([32]))\n",
    "\n",
    "conv1_c=tf.nn.conv2d(x_input,conv1_w,strides=[1,1,1,1], padding='SAME')+conv1_b\n",
    "conv1_a=tf.nn.relu(conv1_c)\n",
    "\n",
    "#pool 1\n",
    "#32*32*32-> 16*16*32\n",
    "pool1=tf.nn.max_pool(conv1_a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "#conv 2\n",
    "#16*16*32 -> 16*16*64\n",
    "conv2_w=tf.Variable(tf.truncated_normal([3,3,32,64]))\n",
    "conv2_b=tf.Variable(tf.truncated_normal([64]))\n",
    "\n",
    "conv2_c=tf.nn.conv2d(pool1,conv2_w,strides=[1,1,1,1], padding='SAME')+conv2_b\n",
    "conv2_a=tf.nn.relu(conv2_c)\n",
    "\n",
    "#pool 1\n",
    "#16*16*64 -> 8*8*64\n",
    "pool2=tf.nn.max_pool(conv2_a, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "#fc\n",
    "#8*8*64 ->3\n",
    "fc1_w=tf.Variable(tf.truncated_normal([8*8*64,3]))\n",
    "fc1_b=tf.Variable(tf.truncated_normal([3]))\n",
    "\n",
    "fc1_in=tf.reshape(pool2,[-1,8*8*64])\n",
    "fc1_c=tf.matmul(fc1_in,fc1_w)+fc1_b\n",
    "\n",
    "#Prediction, accuracy\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_input_onehot, logits=fc1_c))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "prediction=tf.argmax(fc1_c, 1,name=\"prediction\")\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(y_input_onehot, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32),name=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, train acc 0.312500  test acc 0.418269\n",
      "epoch 20, train acc 0.781250  test acc 0.673077\n",
      "epoch 40, train acc 0.843750  test acc 0.750000\n",
      "epoch 60, train acc 0.781250  test acc 0.802885\n",
      "epoch 80, train acc 0.875000  test acc 0.831731\n",
      "epoch 100, train acc 0.968750  test acc 0.860577\n",
      "epoch 120, train acc 0.968750  test acc 0.884615\n",
      "epoch 140, train acc 1.000000  test acc 0.865385\n",
      "epoch 160, train acc 1.000000  test acc 0.908654\n",
      "epoch 180, train acc 0.968750  test acc 0.903846\n",
      "epoch 200, train acc 1.000000  test acc 0.937500\n",
      "epoch 220, train acc 1.000000  test acc 0.947115\n",
      "epoch 240, train acc 1.000000  test acc 0.947115\n",
      "epoch 260, train acc 1.000000  test acc 0.947115\n",
      "epoch 280, train acc 1.000000  test acc 0.947115\n",
      "epoch 300, train acc 1.000000  test acc 0.947115\n",
      "epoch 320, train acc 1.000000  test acc 0.947115\n",
      "epoch 340, train acc 1.000000  test acc 0.947115\n",
      "epoch 360, train acc 1.000000  test acc 0.947115\n",
      "epoch 380, train acc 1.000000  test acc 0.947115\n",
      "validation acc 0.933014\n"
     ]
    }
   ],
   "source": [
    "#Model test\n",
    "tf.set_random_seed(0)\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for j in range(400):\n",
    "        for i in range(int(train_data.shape[0]/batch_size)):\n",
    "            start_idx=i*batch_size\n",
    "            end_idx=min((i+1)*batch_size,data.shape[0]-1)\n",
    "            cur_x=train_data[start_idx:end_idx,:,:,:]\n",
    "            cur_y=train_cls[start_idx:end_idx]\n",
    "            train_step.run(feed_dict={x_input: cur_x, y_input: cur_y})\n",
    "        if j % 20==0:\n",
    "            train_accuracy=accuracy.eval(feed_dict={x_input: cur_x, y_input: cur_y})\n",
    "            test_accuracy=accuracy.eval(feed_dict={x_input: test_data, y_input: test_cls})\n",
    "            print('epoch %d, train acc %f  test acc %f' % (j, train_accuracy,test_accuracy))\n",
    "\n",
    "    print('validation acc %g' % accuracy.eval(feed_dict={x_input: val_data, y_input: val_cls}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, training accuracy 0\n",
      "epoch 20, training accuracy 0.03125\n",
      "epoch 40, training accuracy 0.21875\n",
      "epoch 60, training accuracy 0.3125\n",
      "epoch 80, training accuracy 0.40625\n",
      "epoch 100, training accuracy 0.625\n",
      "epoch 120, training accuracy 0.59375\n",
      "epoch 140, training accuracy 0.84375\n",
      "epoch 160, training accuracy 0.875\n",
      "epoch 180, training accuracy 0.875\n",
      "epoch 200, training accuracy 0.8125\n",
      "epoch 220, training accuracy 0.90625\n",
      "epoch 240, training accuracy 0.96875\n",
      "epoch 260, training accuracy 0.96875\n",
      "epoch 280, training accuracy 0.90625\n",
      "epoch 300, training accuracy 0.90625\n",
      "epoch 320, training accuracy 0.96875\n",
      "epoch 340, training accuracy 0.96875\n",
      "epoch 360, training accuracy 0.96875\n",
      "epoch 380, training accuracy 0.96875\n",
      "all data accuracy 1\n"
     ]
    }
   ],
   "source": [
    "#Training final model (using all data)\n",
    "tf.set_random_seed(0)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    count=0\n",
    "    for j in range(400):\n",
    "        for i in range(int(data.shape[0]/batch_size)):\n",
    "            count+=1\n",
    "            start_idx=i*batch_size\n",
    "            end_idx=min((i+1)*batch_size,data.shape[0]-1)\n",
    "            cur_x=data[start_idx:end_idx,:,:,:]\n",
    "            cur_y=cls[start_idx:end_idx]\n",
    "            train_step.run(feed_dict={x_input: cur_x, y_input: cur_y})\n",
    "        if j % 20==0:\n",
    "            train_accuracy = accuracy.eval(feed_dict={x_input: cur_x, y_input: cur_y})\n",
    "            print('epoch %d, training accuracy %g' % (j, train_accuracy))\n",
    "\n",
    "    print('all data accuracy %g' % accuracy.eval(feed_dict={x_input: data, y_input: cls}))\n",
    "    predicted_cls=prediction.eval(feed_dict={x_input: data})\n",
    "    \n",
    "    #Save model\n",
    "    save_path = saver.save(sess, \"./tl_classifier.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./tl_classifier.ckpt\n",
      "all data accuracy 1\n"
     ]
    }
   ],
   "source": [
    "#Loading test\n",
    "with tf.Session() as sess:\n",
    "    saver = tf.train.import_meta_graph(\"tl_classifier.ckpt.meta\")\n",
    "    saver.restore(sess, \"./tl_classifier.ckpt\")\n",
    "    x_input=sess.graph.get_tensor_by_name(\"x_input:0\")\n",
    "    y_input=sess.graph.get_tensor_by_name(\"y_input:0\")\n",
    "    prediction=sess.graph.get_tensor_by_name(\"prediction:0\")\n",
    "    accuracy=sess.graph.get_tensor_by_name(\"accuracy:0\")\n",
    "    print('all data accuracy %g' % accuracy.eval(feed_dict={x_input: data.astype(np.float64), y_input: cls}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
